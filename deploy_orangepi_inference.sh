#!/bin/bash

# Deploy Vintern-1B inference to Orange Pi using llama.cpp
# Run this script ON Raspberry Pi

set -e

ORANGEPI_IP="192.168.1.16"
ORANGEPI_USER="orangepi"

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘   Deploy Vintern-1B Inference lÃªn Orange Pi RV2         â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“‹ OVERVIEW:"
echo "   â€¢ Orange Pi: RISC-V CPU â†’ dÃ¹ng llama.cpp (C++)"
echo "   â€¢ Model: Vintern-1B â†’ convert sang GGUF Q8_0"
echo "   â€¢ API: Port 8003 (wrapper), 8002 (llama-server)"
echo "   â€¢ KhÃ´ng cÃ²n PROXY loop!"
echo ""

# Check SSH connectivity
echo "ğŸ” Checking SSH connection to Orange Pi..."
if ! ssh -o BatchMode=yes -o ConnectTimeout=5 "$ORANGEPI_USER@$ORANGEPI_IP" exit 2>/dev/null; then
    echo "âš ï¸  SSH key not set up. You'll need to enter password multiple times."
    echo ""
fi

# Load Hugging Face token from .env
HF_TOKEN=""
if [ -f "backend/.env" ]; then
    HF_TOKEN=$(grep "HUGGINGFACE_TOKEN=" backend/.env | cut -d'=' -f2)
fi
if [ -z "$HF_TOKEN" ] && [ -f ".env" ]; then
    HF_TOKEN=$(grep "HUGGINGFACE_TOKEN=" .env | cut -d'=' -f2)
fi

if [ -z "$HF_TOKEN" ]; then
    echo "âš ï¸  HUGGINGFACE_TOKEN not found in .env files"
    read -p "Enter Hugging Face token (hf_xxx): " HF_TOKEN
fi

echo "âœ“ Hugging Face token loaded"
echo ""

# Copy setup script to Orange Pi
echo "ğŸ“¤ Copying setup script to Orange Pi..."
scp setup_orangepi_llamacpp.sh "$ORANGEPI_USER@$ORANGEPI_IP:~/"

echo "âœ“ Script copied"
echo ""

# Execute setup on Orange Pi
echo "ğŸš€ Running setup on Orange Pi..."
echo "   (This will take 15-30 minutes - building llama.cpp + convert model)"
echo ""
read -p "Continue? (y/n) " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Cancelled."
    exit 0
fi

# Run setup with token
ssh -t "$ORANGEPI_USER@$ORANGEPI_IP" "export HUGGINGFACE_TOKEN='$HF_TOKEN' && bash ~/setup_orangepi_llamacpp.sh"

if [ $? -ne 0 ]; then
    echo "âŒ Setup failed on Orange Pi"
    exit 1
fi

echo ""
echo "âœ“ Setup completed on Orange Pi"
echo ""

# Start services on Orange Pi
echo "ğŸš€ Starting services on Orange Pi..."
ssh "$ORANGEPI_USER@$ORANGEPI_IP" << 'REMOTE_COMMANDS'
sudo systemctl stop vllm-service 2>/dev/null || true
sudo systemctl disable vllm-service 2>/dev/null || true

sudo systemctl enable vintern-llamacpp
sudo systemctl start vintern-llamacpp
sleep 5
sudo systemctl enable vintern-wrapper
sudo systemctl start vintern-wrapper
sleep 3

echo ""
echo "ğŸ“Š Service status:"
sudo systemctl status vintern-llamacpp --no-pager -l | head -20
echo ""
sudo systemctl status vintern-wrapper --no-pager -l | head -20
REMOTE_COMMANDS

echo ""
echo "âœ“ Services started on Orange Pi"
echo ""

# Test Orange Pi API
echo "ğŸ§ª Testing Orange Pi API..."
sleep 2

HEALTH_RESPONSE=$(curl -s http://$ORANGEPI_IP:8003/health || echo "FAILED")
if [[ "$HEALTH_RESPONSE" == *"healthy"* ]]; then
    echo "âœ“ Orange Pi API is healthy!"
    echo "   Response: $HEALTH_RESPONSE"
else
    echo "âš ï¸  Orange Pi API not ready yet"
    echo "   Wait a few minutes and check: curl http://$ORANGEPI_IP:8003/health"
fi

echo ""

# Update Raspberry Pi backend configuration
echo "âš™ï¸  Updating Raspberry Pi backend configuration..."
echo ""

BACKEND_ENV="/home/pi/Projects/Vintern-1b-v3.5-demo/backend/.env"

if [ -f "$BACKEND_ENV" ]; then
    # Backup
    cp "$BACKEND_ENV" "$BACKEND_ENV.backup.$(date +%Y%m%d_%H%M%S)"
    
    # Update VLLM_SERVICE_URL to point to wrapper (port 8003)
    if grep -q "VLLM_SERVICE_URL" "$BACKEND_ENV"; then
        sed -i 's|^VLLM_SERVICE_URL=.*|VLLM_SERVICE_URL=http://192.168.1.16:8003|' "$BACKEND_ENV"
        echo "âœ“ Updated VLLM_SERVICE_URL in backend/.env"
    else
        echo "VLLM_SERVICE_URL=http://192.168.1.16:8003" >> "$BACKEND_ENV"
        echo "âœ“ Added VLLM_SERVICE_URL to backend/.env"
    fi
    
    # Comment out old proxy settings if exists
    sed -i 's|^BACKEND_INFERENCE_URL=|#BACKEND_INFERENCE_URL=|' "$BACKEND_ENV" 2>/dev/null || true
else
    echo "âš ï¸  backend/.env not found, creating..."
    cat > "$BACKEND_ENV" <<EOF
# VLLM Service on Orange Pi (llama.cpp)
VLLM_SERVICE_URL=http://192.168.1.16:8003

# Camera Configuration
CAMERA1_URL=rtsp://admin:@192.168.1.4:554/stream1
CAMERA2_URL=rtsp://admin:@192.168.1.7:554/stream1

# Detection Service
DETECTION_SERVICE_URL=http://localhost:8001
MOCK_MODE=true
EOF
    echo "âœ“ Created backend/.env"
fi

echo ""

# Restart backend to apply changes
echo "ğŸ”„ Restarting backend Docker container..."
cd /home/pi/Projects/Vintern-1b-v3.5-demo
docker-compose restart backend

echo ""
echo "â³ Waiting for backend to restart..."
sleep 5

# Test full system
echo ""
echo "ğŸ§ª Testing complete system..."
echo ""

BACKEND_HEALTH=$(curl -s http://localhost:8000/api/health)
echo "Backend health:"
echo "$BACKEND_HEALTH" | python3 -m json.tool 2>/dev/null || echo "$BACKEND_HEALTH"

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘              âœ“ DEPLOYMENT HOÃ€N Táº¤T!                     â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“Š KIáº¾N TRÃšC Má»šI:"
echo ""
echo "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "   â”‚  Raspberry Pi 4     â”‚  â† Web UI + Backend"
echo "   â”‚  192.168.1.14:8000  â”‚"
echo "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo "              â”‚"
echo "              â”‚ VLLM requests"
echo "              â†“"
echo "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "   â”‚  Orange Pi RV2      â”‚  â† Inference Engine"
echo "   â”‚  192.168.1.16:8003  â”‚     (llama.cpp)"
echo "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo ""
echo "âœ“ KhÃ´ng cÃ²n circular dependency!"
echo "âœ“ Vintern-1B cháº¡y native trÃªn Orange Pi RISC-V"
echo "âœ“ API wrapper tÆ°Æ¡ng thÃ­ch vá»›i backend"
echo ""
echo "ğŸŒ TEST Há»† THá»NG:"
echo "   1. Web UI: http://192.168.1.14:8000"
echo "   2. Click 'Analyze with AI' trÃªn camera báº¥t ká»³"
echo "   3. Hoáº·c enable 'Continuous Analysis'"
echo ""
echo "ğŸ“Š MONITOR LOGS:"
echo "   Orange Pi:"
echo "     ssh orangepi@192.168.1.16"
echo "     sudo journalctl -u vintern-llamacpp -f"
echo "     sudo journalctl -u vintern-wrapper -f"
echo ""
echo "   Raspberry Pi:"
echo "     docker logs -f backend"
echo ""
echo "âš¡ PERFORMANCE:"
echo "   â€¢ Orange Pi RV2 xá»­ lÃ½ AI inference"
echo "   â€¢ Raspberry Pi 4 xá»­ lÃ½ cameras + web"
echo "   â€¢ Model GGUF Q8_0 tá»‘i Æ°u cho CPU"
echo ""
