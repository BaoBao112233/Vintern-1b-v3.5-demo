# üéØ QUICK REFERENCE - Raspberry Pi Integration

## üì¶ 1. Transfer Package to Pi

```bash
# Copy package to Pi
scp pi-deployment-package.tar.gz pi@<PI_IP>:~/
```

## üçì 2. Setup on Pi

```bash
# On Raspberry Pi
tar -xzf pi-deployment-package.tar.gz
cd pi-deployment-package
./setup_on_pi.sh

# Update PC IP
nano client/vision_service_example.py  # Line 43: pc_host="YOUR_PC_IP"
```

## ‚úÖ 3. Test Connection

```bash
cd client
python3 test_connection.py 192.168.1.3  # Replace with your PC IP
```

## üî• 4. READY-TO-USE PROMPTS

### A. Simple Quick Analysis (Fast)

```python
from client.vision_service_example import VisionAIService
from PIL import Image

service = VisionAIService(pc_host="192.168.1.3", pc_port=8080)
image = Image.open("frame.jpg")

result = service.analyze_simple(image)
print(result["description"])
```

**Use Cases:**
- Real-time monitoring
- Quick frame description
- Alert systems

**Latency:** ~2-3 seconds (CPU)

---

### B. Comprehensive Detailed Analysis (Recommended ‚≠ê)

```python
from client.vision_service_example import VisionAIService
from PIL import Image

service = VisionAIService(pc_host="192.168.1.3", pc_port=8080)
image = Image.open("frame.jpg")

result = service.analyze_comprehensive(image)

print("Summary:", result["summary"])
print("\nPhases:")
for phase, content in result["phases"].items():
    print(f"  {phase}: {content}")
```

**Use Cases:**
- Detailed scene analysis
- Investigation/review
- Report generation

**Latency:** ~10-15 seconds (multiple turns)

---

### C. Integration with YOLO Detection

```python
from client.vision_service_example import VisionAIService
from PIL import Image

service = VisionAIService(pc_host="192.168.1.3", pc_port=8080)
image = Image.open("frame.jpg")

# Your YOLO detections
yolo_results = [
    {"label": "person", "confidence": 0.95, "bbox": [100, 150, 300, 450]},
    {"label": "car", "confidence": 0.88, "bbox": [400, 200, 700, 500]}
]

result = service.analyze_with_yolo(image, yolo_results)

print(f"VLM sees: {result['vlm_description']}")
print(f"Verification: {result['verification']}")
print(f"Confidence: {result['confidence']:.2%}")
```

**Use Cases:**
- Verify YOLO detections
- Cross-reference with VLM
- Improve detection confidence

---

### D. Custom Questions

```python
from client.vision_service_example import VisionAIService
from PIL import Image

service = VisionAIService(pc_host="192.168.1.3", pc_port=8080)
image = Image.open("frame.jpg")

# Ask specific questions
questions = [
    "C√≥ bao nhi√™u ng∆∞·ªùi trong ·∫£nh?",
    "Ng∆∞·ªùi n√†o ƒëang l√†m g√¨?",
    "C√≥ h√†nh vi b·∫•t th∆∞·ªùng kh√¥ng?",
    "Th·ªùi ti·∫øt nh∆∞ th·∫ø n√†o?"
]

for q in questions:
    result = service.analyze_simple(image, custom_prompt=q)
    print(f"Q: {q}")
    print(f"A: {result['description']}\n")
```

---

## üåê 5. FastAPI Endpoints

### Add to your `backend/app/main.py`:

```python
from fastapi import FastAPI
from .api import vision_endpoints  # Copy fastapi_endpoints_example.py

app = FastAPI()
app.include_router(vision_endpoints.router)
```

### Available Endpoints:

```bash
# Health check
GET /api/vision/health

# Quick analysis
POST /api/vision/analyze/quick
  -F "file=@image.jpg"

# Detailed analysis
POST /api/vision/analyze/detailed
  -F "file=@image.jpg"

# With YOLO
POST /api/vision/analyze/with-yolo
  -F "file=@image.jpg"
  -F 'detections=[{"label":"person","confidence":0.95,"bbox":[100,150,300,450]}]'

# Custom prompt
POST /api/vision/analyze/custom
  -F "file=@image.jpg"
  -F "prompt=C√≥ bao nhi√™u ng∆∞·ªùi?"

# RTSP frame
POST /api/vision/analyze/rtsp-frame
  -d '{"camera_id":"cam1","frame_data":"base64_jpeg","include_detections":true}'
```

---

## üí° 6. BEST PROMPTS (Ti·∫øng Vi·ªát)

### General Description
```python
"M√¥ t·∫£ chi ti·∫øt nh·ªØng g√¨ b·∫°n th·∫•y trong ·∫£nh."
"B·∫°n th·∫•y g√¨ trong ·∫£nh n√†y? K·ªÉ c·∫£ m√†u s·∫Øc, v·∫≠t th·ªÉ, v·ªã tr√≠."
```

### Object Counting
```python
"C√≥ bao nhi√™u ng∆∞·ªùi trong ·∫£nh? ƒê·∫øm c·ª• th·ªÉ."
"Li·ªát k√™ t·∫•t c·∫£ c√°c v·∫≠t th·ªÉ v√† s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i."
```

### Behavior Analysis
```python
"Ng∆∞·ªùi trong ·∫£nh ƒëang l√†m g√¨?"
"C√≥ h√†nh vi b·∫•t th∆∞·ªùng ho·∫∑c ƒë√°ng ng·ªù n√†o kh√¥ng?"
"M·ªçi ng∆∞·ªùi ƒëang t∆∞∆°ng t√°c nh∆∞ th·∫ø n√†o?"
```

### Safety & Security
```python
"C√≥ d·∫•u hi·ªáu nguy hi·ªÉm n√†o trong ·∫£nh kh√¥ng?"
"M√¥i tr∆∞·ªùng c√≥ an to√†n kh√¥ng? Gi·∫£i th√≠ch."
"Ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng v·ªÅ an ninh."
```

### Vehicle Analysis
```python
"C√≥ ph∆∞∆°ng ti·ªán g√¨ trong ·∫£nh? M√†u g√¨? Lo·∫°i g√¨?"
"Bi·ªÉn s·ªë xe c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c kh√¥ng?"
"Xe ƒëang ·ªü v·ªã tr√≠ n√†o?"
```

### Environment
```python
"ƒê√¢y l√† m√¥i tr∆∞·ªùng g√¨? Trong nh√† hay ngo√†i tr·ªùi?"
"Th·ªùi ti·∫øt nh∆∞ th·∫ø n√†o?"
"√Ånh s√°ng ban ng√†y hay ban ƒë√™m?"
```

### Multi-Phase Questions (Best Results ‚≠ê)
```python
questions = {
    "overview": "M√¥ t·∫£ t·ªïng quan b·ª©c ·∫£nh.",
    "people": "C√≥ ng∆∞·ªùi kh√¥ng? H·ªç ƒëang l√†m g√¨?",
    "objects": "C√≥ v·∫≠t th·ªÉ g√¨ ƒë√°ng ch√∫ √Ω?",
    "safety": "C√≥ ƒëi·ªÉm b·∫•t th∆∞·ªùng v·ªÅ an ninh kh√¥ng?",
    "details": "Chi ti·∫øt quan tr·ªçng kh√°c?"
}
```

---

## üìä 7. Performance Expectations

| Analysis Type | Latency (CPU) | Tokens | Quality |
|--------------|---------------|--------|---------|
| Quick | ~2-3s | ~340 | ‚≠ê‚≠ê‚≠ê |
| Detailed | ~10-15s | ~1000+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| YOLO+VLM | ~3-5s | ~400 | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Custom | ~2-3s | ~340 | ‚≠ê‚≠ê‚≠ê |

**Note:** With GPU (rebuild with CUDA) ‚Üí 5-10x faster!

---

## üîß 8. Integration Examples

### A. RTSP Camera Stream

```python
import cv2
from client.vision_service_example import VisionAIService
from PIL import Image

service = VisionAIService(pc_host="192.168.1.3")

# Open RTSP stream
cap = cv2.VideoCapture("rtsp://admin:pass@192.168.1.4/stream")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Analyze every 30 frames (1 second at 30fps)
    if frame_count % 30 == 0:
        # Convert to PIL
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        # Quick analysis
        result = service.analyze_simple(image)
        
        print(f"Frame {frame_count}: {result['description']}")
    
    frame_count += 1
```

### B. Motion-Triggered Analysis

```python
from client.vision_service_example import VisionAIService
import time

service = VisionAIService(pc_host="192.168.1.3")

def on_motion_detected(frame):
    """Callback khi ph√°t hi·ªán chuy·ªÉn ƒë·ªông"""
    
    # Detailed analysis
    result = service.analyze_comprehensive(frame)
    
    if "ng∆∞·ªùi" in result["summary"].lower():
        # Alert: c√≥ ng∆∞·ªùi
        send_alert(result["summary"])
    
    # Log
    save_to_database(result)
```

### C. Scheduled Monitoring

```python
from client.vision_service_example import VisionAIService
import schedule
import time

service = VisionAIService(pc_host="192.168.1.3")

def analyze_camera():
    """Ch·∫°y ƒë·ªãnh k·ª≥ m·ªói 5 ph√∫t"""
    frame = capture_frame_from_camera()
    result = service.analyze_simple(frame)
    
    print(f"[{time.strftime('%H:%M:%S')}] {result['description']}")

# Schedule
schedule.every(5).minutes.do(analyze_camera)

while True:
    schedule.run_pending()
    time.sleep(1)
```

---

## üö® 9. Error Handling

```python
from client.vision_service_example import VisionAIService

service = VisionAIService(pc_host="192.168.1.3", max_retries=2)

try:
    result = service.analyze_simple(image)
    
    if not result["success"]:
        print(f"Analysis failed: {result.get('error')}")
        # Fallback logic
        
except ConnectionError:
    print("PC server not reachable")
    # Use cached results or skip
    
except TimeoutError:
    print("Request timeout")
    # Retry later
```

---

## üìö 10. Full Documentation

- **PI_INTEGRATION_GUIDE.md** - Complete integration guide
- **OUTPUT_LIMITATION.md** - Why model outputs are short
- **client/README.md** - Client API reference
- **ARCHITECTURE.md** - System architecture

---

## ‚úÖ Checklist

- [ ] Package transferred to Pi
- [ ] Dependencies installed (`./setup_on_pi.sh`)
- [ ] PC IP configured in scripts
- [ ] Connection tested (`test_connection.py`)
- [ ] Quick analysis works
- [ ] Integrated into backend
- [ ] RTSP cameras connected
- [ ] Production deployment

---

**üéØ Everything you need is ready! Start integrating now!**

File locations:
- Package: `/home/baobao/Projects/Vintern-1b-v3.5-demo/pi-deployment-package.tar.gz`
- Guide: `PI_INTEGRATION_GUIDE.md`
- Examples: `client/vision_service_example.py`
- Endpoints: `client/fastapi_endpoints_example.py`
