# üé• H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng H·ªá Th·ªëng Camera + VLLM

H·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ k·∫øt n·ªëi camera Dahua v·ªõi backend API t√≠ch h·ª£p VLLM.

## üìã Th√¥ng Tin C·∫•u H√¨nh

### Camera
- **Camera 1**: 192.168.1.4 
- **Camera 2**: 192.168.1.7
- **Username**: admin
- **Password**: abcd12345
- **RTSP URL**: `rtsp://admin:abcd12345@192.168.1.{4|7}/cam/realmonitor?channel=1&subtype=1`

### Backend API
- **Host**: 192.168.1.14 (Raspberry Pi)
- **Port**: 8005
- **URL**: http://192.168.1.14:8005
- **Documentation**: http://192.168.1.14:8005/docs

### VLLM Service
- **Backend hi·ªán t·∫°i**: HuggingFace API
- **Model**: 5CD-AI/Vintern-1B-v3_5
- **Token**: ƒê√£ c·∫•u h√¨nh trong .env

## üöÄ Kh·ªüi ƒê·ªông H·ªá Th·ªëng

### 1. Kh·ªüi ƒë·ªông Backend Service

```bash
cd /home/pi/Projects/Vintern-1b-v3.5-demo

# Ch·∫°y backend tr√™n port 8005
HOST_IP=0.0.0.0 BACKEND_PORT=8005 python3 backend_service.py > /tmp/backend.log 2>&1 &

# Ki·ªÉm tra log
tail -f /tmp/backend.log
```

### 2. Ki·ªÉm Tra Tr·∫°ng Th√°i

```bash
# Health check
curl http://localhost:8005/health | python3 -m json.tool

# Danh s√°ch cameras
curl http://localhost:8005/api/cameras | python3 -m json.tool
```

## üéØ S·ª≠ D·ª•ng API

### 1. Ch·ª•p Frame T·ª´ Camera

```bash
# Camera 1
curl http://localhost:8005/api/capture/1 -o camera1.jpg

# Camera 2
curl http://localhost:8005/api/capture/2 -o camera2.jpg
```

### 2. Ph√¢n T√≠ch Frame v·ªõi VLLM

#### S·ª≠ d·ª•ng curl:
```bash
curl -X POST http://localhost:8005/api/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "camera_id": 1,
    "prompt": "M√¥ t·∫£ nh·ªØng g√¨ b·∫°n th·∫•y trong ·∫£nh. C√≥ ng∆∞·ªùi kh√¥ng? C√≥ xe kh√¥ng?",
    "save_frame": true
  }' | python3 -m json.tool
```

#### S·ª≠ d·ª•ng Python:
```python
import requests
import json

# Ph√¢n t√≠ch camera 1
response = requests.post(
    "http://localhost:8005/api/analyze",
    json={
        "camera_id": 1,
        "prompt": "Describe what you see. Any people or vehicles?",
        "save_frame": True
    }
)

result = response.json()
if result['success']:
    print(f"Analysis: {result['response']}")
    print(f"Latency: {result['latency_ms']:.1f}ms")
else:
    print(f"Error: {result['error']}")
```

### 3. Monitor Li√™n T·ª•c (Server-Sent Events)

```bash
# Monitor camera 1, 5 gi√¢y/l·∫ßn, t·ªëi ƒëa 10 l·∫ßn
curl -N http://localhost:8005/api/monitor/1?interval=5&max_iterations=10
```

## üõ†Ô∏è Scripts Ti·ªán √çch

### 1. Test Backend API

```bash
cd /home/pi/Projects/Vintern-1b-v3.5-demo

# Test t·∫•t c·∫£
python3 test_backend_api.py

# Test ch·ªâ capture
python3 test_backend_api.py --test capture --camera 1

# Test ph√¢n t√≠ch
python3 test_backend_api.py --test analyze --camera 1
```

### 2. Analyze Camera (Standalone)

```bash
# Ph√¢n t√≠ch camera 1, 5 gi√¢y/l·∫ßn, t·ªëi ƒëa 3 l·∫ßn
python3 analyze_camera.py --camera 1 --interval 5 --max-iterations 3 --save-frames

# Ch·∫°y li√™n t·ª•c (Ctrl+C ƒë·ªÉ d·ª´ng)
python3 analyze_camera.py --camera 2 --interval 10 --save-frames
```

## üìä API Endpoints

| Method | Endpoint | M√¥ T·∫£ |
|--------|----------|-------|
| GET | `/health` | Ki·ªÉm tra tr·∫°ng th√°i service |
| GET | `/api/cameras` | Danh s√°ch cameras |
| GET | `/api/capture/{camera_id}` | Ch·ª•p frame t·ª´ camera |
| POST | `/api/analyze` | Ph√¢n t√≠ch frame v·ªõi VLLM |
| GET | `/api/monitor/{camera_id}` | Monitor li√™n t·ª•c (SSE) |

## üîß C·∫•u H√¨nh VLLM Backend

H·ªá th·ªëng h·ªó tr·ª£ 3 lo·∫°i backend:

### 1. HuggingFace API (Hi·ªán t·∫°i)
```bash
# Trong .env
VLM_BACKEND=hf
HUGGINGFACE_TOKEN=your_token_here
```

**L∆∞u √Ω**: HuggingFace Inference API c√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh ho·∫∑c model kh√¥ng kh·∫£ d·ª•ng.

### 2. Local VLLM Service
```bash
# Trong .env
VLM_BACKEND=vllm
VLLM_SERVICE_URL=http://192.168.1.16:8003
```

**Y√™u c·∫ßu**: C·∫ßn c√≥ VLLM service (llama.cpp) ch·∫°y tr√™n m√°y kh√°c trong m·∫°ng LAN.

### 3. PC Inference Server
```bash
# Trong .env
VLM_BACKEND=pc
VLLM_SERVICE_URL=http://192.168.1.100:8080
```

**Y√™u c·∫ßu**: C·∫ßn setup PC theo h∆∞·ªõng d·∫´n trong `pc-inference-server/README.md`

## üîç Troubleshooting

### Camera kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c

```bash
# Test RTSP tr·ª±c ti·∫øp v·ªõi ffmpeg
ffmpeg -rtsp_transport tcp -i "rtsp://admin:abcd12345@192.168.1.4/cam/realmonitor?channel=1&subtype=1" -frames:v 1 test.jpg
```

### Backend service kh√¥ng kh·ªüi ƒë·ªông

```bash
# Ki·ªÉm tra process
ps aux | grep backend_service

# Ki·ªÉm tra log
tail -50 /tmp/backend.log

# Ki·ªÉm tra port
lsof -i :8005
```

### VLLM ph√¢n t√≠ch l·ªói

1. **HuggingFace API kh√¥ng kh·∫£ d·ª•ng**: 
   - Model c√≥ th·ªÉ kh√¥ng h·ªó tr·ª£ Inference API
   - Chuy·ªÉn sang s·ª≠ d·ª•ng PC inference server

2. **Local VLLM kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c**:
   ```bash
   # Ki·ªÉm tra connection
   curl http://192.168.1.16:8003/health
   ```

## üìù V√≠ D·ª• T√≠ch H·ª£p

### Backend FastAPI Service

```python
from app.services.rtsp_camera import RTSPCamera
from app.services.vintern_client import VinternClient

# Kh·ªüi t·∫°o
camera = RTSPCamera(
    "rtsp://admin:password@192.168.1.4/cam/realmonitor?channel=1&subtype=1",
    "Camera_1"
)

vlm = VinternClient(
    hf_token="your_token",
    vllm_url="http://192.168.1.16:8003",
    backend="vllm"  # ho·∫∑c "hf" ho·∫∑c "pc"
)

# Capture v√† ph√¢n t√≠ch
result = camera.capture_frame()
if result:
    _, frame_bytes = result
    analysis = vlm.analyze_image(
        frame_bytes,
        "Describe what you see"
    )
    print(analysis['response'])
```

### Smart Analysis (nhi·ªÅu c√¢u h·ªèi)

Tham kh·∫£o `smart_analyze.py` ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt b·∫±ng nhi·ªÅu c√¢u h·ªèi li√™n ti·∫øp:

```bash
# Ch·ª•p frame tr∆∞·ªõc
curl http://localhost:8005/api/capture/1 -o test.jpg

# Ph√¢n t√≠ch smart
python3 smart_analyze.py test.jpg
```

**L∆∞u √Ω**: `smart_analyze.py` hi·ªán ch·ªâ ho·∫°t ƒë·ªông khi c√≥ PC inference server ho·∫∑c local VLLM ƒëang ch·∫°y.

## üéØ Next Steps

1. **Setup PC Inference Server** (khuy·∫øn ngh·ªã):
   - Xem `pc-inference-server/README.md`
   - Download model Vintern-1B-v3.5 GGUF
   - Ch·∫°y llama-server tr√™n PC

2. **T√≠ch h·ª£p Detection Service**:
   - S·ª≠ d·ª•ng Coral USB accelerator (n·∫øu c√≥)
   - Object detection tr∆∞·ªõc khi g·ª≠i VLLM

3. **Setup Frontend**:
   - React app ƒë·ªÉ hi·ªÉn th·ªã camera feeds
   - Real-time analysis results
   - Chat interface

## üìû Li√™n H·ªá / Support

- Xem th√™m: `ARCHITECTURE.md`, `PI_INTEGRATION_GUIDE.md`
- API Docs: http://192.168.1.14:8005/docs
