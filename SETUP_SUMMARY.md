# ğŸ“‹ TÃ“M Táº®T SETUP Há»† THá»NG

## âœ… ÄÃ£ HoÃ n ThÃ nh

### 1. Backend API Service âœ“
- **File**: `backend_service.py`
- **Port**: 8005
- **Status**: Äang cháº¡y (PID: 328040)
- **Features**:
  - Káº¿t ná»‘i 2 cameras Dahua qua RTSP
  - API endpoints Ä‘á»ƒ capture vÃ  analyze frames
  - TÃ­ch há»£p VLLM client (HuggingFace, local VLLM, PC inference)
  - Real-time monitoring vá»›i Server-Sent Events

### 2. Camera Integration âœ“
- **Camera 1**: 192.168.1.4 - âœ… ÄÃ£ test thÃ nh cÃ´ng
- **Camera 2**: 192.168.1.7 - âœ… ÄÃ£ test thÃ nh cÃ´ng
- **Protocol**: RTSP over TCP
- **Resolution**: 640x360 (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)

### 3. VLLM Client âœ“
- **File**: `backend/app/services/vintern_client.py`
- **Backends há»— trá»£**:
  - HuggingFace Inference API (hiá»‡n táº¡i)
  - Local VLLM service (khi cÃ³)
  - PC Inference Server (khi cÃ³)

### 4. Scripts vÃ  Tools âœ“
- `analyze_camera.py` - Standalone script phÃ¢n tÃ­ch camera
- `test_backend_api.py` - Test client cho API
- `start_system.sh` - Quick start script
- `backend/app/services/rtsp_camera.py` - RTSP camera service
- `backend/app/services/vintern_client.py` - VLM client

### 5. Documentation âœ“
- `CAMERA_SETUP_GUIDE.md` - HÆ°á»›ng dáº«n chi tiáº¿t
- API docs tá»± Ä‘á»™ng táº¡i: http://192.168.1.14:8005/docs

## ğŸ¯ API Endpoints ÄÃ£ Test

| Endpoint | Status | MÃ´ Táº£ |
|----------|--------|-------|
| `GET /health` | âœ… | Health check - OK |
| `GET /api/cameras` | âœ… | List cameras - 2 cameras |
| `GET /api/capture/1` | âœ… | Capture camera 1 - 39KB |
| `GET /api/capture/2` | âœ… | Capture camera 2 - 81KB |
| `POST /api/analyze` | âš ï¸ | VLM analysis - HF API unstable |

## âš ï¸ LÆ°u Ã Quan Trá»ng

### HuggingFace Inference API
- Model `5CD-AI/Vintern-1B-v3_5` cÃ³ thá»ƒ **khÃ´ng kháº£ dá»¥ng** trÃªn HF Inference API
- VQA vÃ  Chat Completion API Ä‘á»u failed
- **Khuyáº¿n nghá»‹**: Setup PC Inference Server vá»›i llama.cpp

### Next Steps Ä‘á»ƒ VLLM hoáº¡t Ä‘á»™ng

#### Option 1: PC Inference Server (Khuyáº¿n nghá»‹)
```bash
# TrÃªn PC (cÃ³ GPU):
1. Download model Vintern-1B-v3.5 GGUF
2. CÃ i llama.cpp
3. Cháº¡y llama-server 
4. Update .env trÃªn Pi:
   VLM_BACKEND=pc
   VLLM_SERVICE_URL=http://<PC_IP>:8080
```

#### Option 2: Orange Pi VLLM Service
```bash
# Náº¿u Orange Pi (192.168.1.16) cÃ³ VLLM:
1. Kiá»ƒm tra service Ä‘ang cháº¡y
2. Update .env:
   VLM_BACKEND=vllm
   VLLM_SERVICE_URL=http://192.168.1.16:8003
```

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng Ngay

### Khá»Ÿi Äá»™ng Há»‡ Thá»‘ng
```bash
cd /home/pi/Projects/Vintern-1b-v3.5-demo

# CÃ¡ch 1: DÃ¹ng script tá»± Ä‘á»™ng
./start_system.sh

# CÃ¡ch 2: Manual
HOST_IP=0.0.0.0 BACKEND_PORT=8005 python3 backend_service.py > /tmp/backend.log 2>&1 &
```

### Test Cameras
```bash
# Test capture camera 1
python3 test_backend_api.py --test capture --camera 1

# Test capture camera 2
python3 test_backend_api.py --test capture --camera 2

# Hoáº·c dÃ¹ng curl
curl http://localhost:8005/api/capture/1 -o camera1.jpg
curl http://localhost:8005/api/capture/2 -o camera2.jpg
```

### Monitor LiÃªn Tá»¥c
```bash
# Chá»¥p vÃ  phÃ¢n tÃ­ch má»—i 5 giÃ¢y
python3 analyze_camera.py --camera 1 --interval 5 --save-frames

# Ctrl+C Ä‘á»ƒ dá»«ng
```

### API Examples

#### Python
```python
import requests

# Capture frame
response = requests.get("http://localhost:8005/api/capture/1")
with open("camera.jpg", "wb") as f:
    f.write(response.content)

# Analyze (khi VLLM hoáº¡t Ä‘á»™ng)
response = requests.post(
    "http://localhost:8005/api/analyze",
    json={
        "camera_id": 1,
        "prompt": "Describe what you see",
        "save_frame": True
    }
)
print(response.json())
```

#### curl
```bash
# Health check
curl http://localhost:8005/health | python3 -m json.tool

# Capture
curl http://localhost:8005/api/capture/1 -o output.jpg

# Analyze
curl -X POST http://localhost:8005/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"camera_id": 1, "prompt": "Describe this image", "save_frame": true}' \
  | python3 -m json.tool
```

## ğŸ“‚ Cáº¥u TrÃºc Files Má»›i

```
Vintern-1b-v3.5-demo/
â”œâ”€â”€ backend_service.py          # Main backend API service âœ¨ Má»šI
â”œâ”€â”€ analyze_camera.py           # Standalone analyzer âœ¨ Má»šI
â”œâ”€â”€ test_backend_api.py         # API test client âœ¨ Má»šI
â”œâ”€â”€ start_system.sh             # Quick start script âœ¨ Má»šI
â”œâ”€â”€ CAMERA_SETUP_GUIDE.md       # HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ âœ¨ Má»šI
â”œâ”€â”€ SETUP_SUMMARY.md            # File nÃ y âœ¨ Má»šI
â”‚
â”œâ”€â”€ backend/app/services/
â”‚   â”œâ”€â”€ rtsp_camera.py          # RTSP camera service âœ¨ Má»šI
â”‚   â””â”€â”€ vintern_client.py       # VLM client âœ¨ Má»šI
â”‚
â”œâ”€â”€ output/                     # Frames Ä‘Æ°á»£c lÆ°u (tá»± táº¡o)
â””â”€â”€ /tmp/backend.log            # Backend service log
```

## ğŸ”§ Troubleshooting

### Backend khÃ´ng khá»Ÿi Ä‘á»™ng
```bash
# Xem log
tail -50 /tmp/backend.log

# Kiá»ƒm tra port
lsof -i :8005

# Kill process cÅ©
pkill -f backend_service.py
```

### Camera khÃ´ng connect
```bash
# Test RTSP trá»±c tiáº¿p
ffmpeg -rtsp_transport tcp \
  -i "rtsp://admin:abcd12345@192.168.1.4/cam/realmonitor?channel=1&subtype=1" \
  -frames:v 1 test.jpg
```

### VLLM khÃ´ng hoáº¡t Ä‘á»™ng
1. Kiá»ƒm tra backend trong .env: `VLM_BACKEND=hf|vllm|pc`
2. Náº¿u dÃ¹ng remote service, check connection:
   ```bash
   curl http://192.168.1.16:8003/health
   ```
3. Xem log Ä‘á»ƒ biáº¿t lá»—i cá»¥ thá»ƒ:
   ```bash
   tail -f /tmp/backend.log
   ```

## ğŸ“Š Performance

- **Camera Frame Capture**: ~1-2 giÃ¢y/frame
- **RTSP Connection**: ~1.5 giÃ¢y káº¿t ná»‘i ban Ä‘áº§u
- **Frame Size**: 35-80 KB (JPEG, 640x360)
- **Backend Response**: < 100ms (khÃ´ng tÃ­nh VLLM)
- **VLLM Latency**: Phá»¥ thuá»™c backend:
  - HF API: 500ms - 2s (khi hoáº¡t Ä‘á»™ng)
  - Local VLLM: 2-5s
  - PC Inference: 1-3s

## ğŸ¯ Káº¿ Hoáº¡ch Tiáº¿p Theo

1. **Setup PC Inference Server**
   - Download Vintern-1B-v3.5 GGUF model
   - Setup llama.cpp vá»›i OpenAI-compatible API
   - Test vá»›i Pi backend

2. **Object Detection Integration**
   - TÃ­ch há»£p Coral USB (náº¿u cÃ³)
   - Hoáº·c dÃ¹ng YOLOv8n trÃªn Pi
   - Pre-filter frames trÆ°á»›c khi gá»­i VLLM

3. **Frontend UI** 
   - React app hiá»ƒn thá»‹ camera feeds
   - Real-time analysis results
   - Control panel Ä‘á»ƒ chá»n camera

4. **Database Logging**
   - LÆ°u analysis results
   - Frame archiving
   - Event detection alerts

## ğŸ“ Files Tham Kháº£o

- `ARCHITECTURE.md` - Kiáº¿n trÃºc há»‡ thá»‘ng
- `PI_INTEGRATION_GUIDE.md` - TÃ­ch há»£p Pi vá»›i PC inference  
- `CAMERA_SETUP_GUIDE.md` - HÆ°á»›ng dáº«n chi tiáº¿t camera setup
- `smart_analyze.py` - VÃ­ dá»¥ phÃ¢n tÃ­ch thÃ´ng minh

## âœ… Summary

**Há»‡ thá»‘ng hiá»‡n táº¡i**:
- âœ… Backend API hoáº¡t Ä‘á»™ng tá»‘t (port 8005)
- âœ… 2 cameras káº¿t ná»‘i thÃ nh cÃ´ng
- âœ… Capture frames hoáº¡t Ä‘á»™ng
- âš ï¸ VLLM analysis cáº§n setup thÃªm (HF API khÃ´ng stable)

**Äá»ƒ sá»­ dá»¥ng Ä‘áº§y Ä‘á»§**: Setup PC Inference Server hoáº·c connect Ä‘áº¿n existing VLLM service.

**Quick Start**: `./start_system.sh`
