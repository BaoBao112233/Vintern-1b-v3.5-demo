# ğŸ“ Quick Start cho Raspberry Pi

HÆ°á»›ng dáº«n nhanh setup Raspberry Pi Ä‘á»ƒ giao tiáº¿p vá»›i PC inference server.

## ğŸ“‹ BÆ°á»›c 1: Chuáº©n Bá»‹ Network

### TrÃªn PC (Ä‘Ã£ setup xong)
```bash
# 1. Láº¥y PC IP
ip addr show | grep "inet " | grep -v "127.0.0.1"
# Example output: 192.168.1.100

# 2. Check server Ä‘ang cháº¡y
curl http://localhost:8080/health
# Should return: {"status":"ok"}

# 3. Má»Ÿ firewall náº¿u cáº§n
sudo ufw allow 8080/tcp
```

### TrÃªn Raspberry Pi

**1. Check network connectivity**
```bash
# Ping PC
ping -c 4 192.168.1.100  # Thay báº±ng IP cá»§a PC

# Check cÃ³ thá»ƒ telnet vÃ o port
nc -zv 192.168.1.100 8080
```

**2. CÃ i Python dependencies**
```bash
# Update packages
sudo apt update
sudo apt install -y python3-pip python3-venv

# Create virtual environment
python3 -m venv ~/vintern-env
source ~/vintern-env/bin/activate

# Install dependencies
pip install requests pillow
```

## ğŸ“¦ BÆ°á»›c 2: Copy Client Code sang Pi

### Option A: Git (khuyáº¿n nghá»‹)
```bash
# TrÃªn Pi
cd ~
# Option 1: Clone full repo
git clone <your-repo-url>
cd Vintern-1b-v3.5-demo/client

# Option 2: Clone and copy only client folder
git clone <your-repo-url>
cp -r Vintern-1b-v3.5-demo/client ~/pi-client
cd ~/pi-client
```

### Option B: SCP tá»« PC
```bash
# TrÃªn PC
cd /home/baobao/Projects/Vintern-1b-v3.5-demo

# Copy client folder sang Pi
scp -r client/ pi@<PI_IP>:~/pi-client/

# Copy verification script
scp verify_network.sh pi@<PI_IP>:~/

# TrÃªn Pi  
cd ~/pi-client
pip install -r requirements.txt
```

### Option C: Download trá»±c tiáº¿p
```bash
# TrÃªn Pi (náº¿u repo Ä‘Ã£ push lÃªn GitHub)
wget https://raw.githubusercontent.com/<user>/Vintern-1b-v3.5-demo/main/client/pc_inference_client.py
wget https://raw.githubusercontent.com/<user>/Vintern-1b-v3.5-demo/main/client/test_connection.py
wget https://raw.githubusercontent.com/<user>/Vintern-1b-v3.5-demo/main/client/requirements.txt
pip install -r requirements.txt
```

## ğŸ§ª BÆ°á»›c 3: Test Connection

**3.1. Quick verification script**
```bash
# TrÃªn Pi
cd ~

# Run verification (pass PC IP as argument)
./verify_network.sh 192.168.1.100

# Expected: All tests PASS
# âœ… Network Ping - PASS
# âœ… Port Check - PASS
# âœ… HTTP Health - PASS
# âœ… Python Dependencies - PASS
```

**3.2. Detailed connection test**
```bash
# TrÃªn Pi
cd ~/pi-client  # hoáº·c ~/client
python test_connection.py 192.168.1.100

# Expected: All tests PASS
# âœ… Network Ping - PASS
# âœ… Port Check - PASS
# âœ… HTTP Health - PASS
# âœ… Bandwidth Test - PASS
```

## ğŸ–¼ï¸ BÆ°á»›c 4: Test Inference

```bash
# TrÃªn Pi, download test image
wget https://raw.githubusercontent.com/opencv/opencv/master/samples/data/fruits.jpg -O test.jpg

# Test inference
python pc_inference_client.py test.jpg "MÃ´ táº£ nhá»¯ng gÃ¬ báº¡n tháº¥y"

# Expected output:
# âœ… PC server is ready!
# âœ… Response:
# [Model's description of the image]
# Time: 2.xx s
```

## ğŸ”§ Troubleshooting

### âŒ Test connection fail?

**1. Ping khÃ´ng thÃ nh cÃ´ng:**
```bash
# TrÃªn Pi
ip addr show  # Check Pi IP
ip route      # Check gateway

# TrÃªn PC  
ip addr show  # Verify PC IP
```

**2. Port khÃ´ng má»Ÿ:**
```bash
# TrÃªn PC
sudo ufw status
sudo ufw allow 8080/tcp

# Check server
ps aux | grep llama-server
netstat -tlnp | grep 8080
```

**3. Firewall block:**
```bash
# TrÃªn PC - temporarily disable (for testing)
sudo ufw disable

# Test tá»« Pi
curl http://192.168.1.100:8080/health

# Re-enable vÃ  má»Ÿ port
sudo ufw enable
sudo ufw allow 8080/tcp
```

### âŒ Inference timeout?

```python
# Edit pc_inference_client.py
client = PCInferenceClient(
    pc_host="192.168.1.100",
    timeout=60  # TÄƒng lÃªn 60 seconds
)
```

### âŒ Slow network?

```bash
# Test bandwidth
# TrÃªn Pi
iperf3 -c 192.168.1.100

# Expected: >90 Mbps for 100Mbps LAN
```

## ğŸ¯ Next: Integrate vÃ o Backend

Sau khi test thÃ nh cÃ´ng, integrate vÃ o backend:

```python
# backend/services/pc_vlm_client.py
from client.pc_inference_client import PCInferenceClient

class PCVLMService:
    def __init__(self, pc_host: str):
        self.client = PCInferenceClient(pc_host=pc_host)
    
    async def analyze_frame(self, frame, prompt: str):
        # Your integration logic
        result = self.client.chat_completion(frame, prompt)
        return result
```

Xem: [Backend Integration Guide](backend/README.md)

## ğŸ“š References

- [Client Library Docs](client/README.md)
- [PC Server Setup](pc-inference-server/README.md)
- [Full Architecture](ARCHITECTURE.md)

---

**Ready!** Giá» Pi Ä‘Ã£ cÃ³ thá»ƒ giao tiáº¿p vá»›i PC! ğŸ‰
